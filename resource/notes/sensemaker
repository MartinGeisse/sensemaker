
Der Sensemaker liest Code ein, baut daraus eine Datenbank / Code-Modell auf, und beantwortet dann Fragen. 

Plugins erweitern den SM um Fähigkeiten. E/EP-System wie gehabt.

Fragen vs. Sinn: hier geht es um eine Formalität. Auch wenn Formal immer eine Frage gestellt werden muss, damit der SM reagiert, kann diese Frage ja auch sein: "Was ist der Sinn dieses Programms?" Die Details sind demnach den Plugins überlassen.

Zentraler Bestandteil wird eine Wissensdatenbank sein -- im Grunde eine lazy gefüllte key/value map. Entsprechende Provider werden registriert, und dann kann aufgrund eines Keys ein Objekt abgefragt werden. (Der Key ist am besten mit dessen Typ parametrisiert). Ist das Objekt nicht da, wird der entsprechende Provider benutzt, um es zu erzeugen, was wiederum auf die Wissensdatenbank zugreifen kann. Idee: Die ursprünglichen Benutzerfragen können auch darüber abgebildet werden. Im Prinzip kann nach jedem Objekt gefragt werden (bzw. nach jedem Objekt, für das ein Renderer existiert, um es dem Benutzer darzustellen).

Initialer Inhalt der Wissensdatenbank ist der Code, bzw. sogar nur die Angabe, wo dieser zu finden ist. (Dann muss aber davon ausgegangen werden, dass er sich nicht mittendrin ändert).

Auch Requests an die Wissensdatenbank sollten renderable sein: Wenn ein Request nicht beantwortet werden kann, dann sollte dieser ausgegeben werden, damit der Benutzer ihn ggf. beantworten kann.

Evtl. sind nicht nur Anfragen an den Code, sondern auch an eine Datenbank nötig -- vor allem, wenn Code in der DB liegt; aber auch z.B. der Struktur, oder ob bestimmte Situationen vorkommen.

Der SM sollte Annahmen ausgeben. Z.B.: In der DB liegen keine Datensätze mit is_old=0, also treffe ich die Annahme, dass dieser Fall insgesamt nicht vorkommen kann.

------------------------------------

Große Frage ist: Soll der SM von Source Code oder von Class Files ausgehen?
- Wenn Source Files: Dann muss im Prinzip ein Compiler Teil des SM sein
- Wenn Class Files: Dann setzt das voraus, dass der Code überhaupt compilebar ist
- Wenn beides angegeben wird, können die beiden inkonsistent sein
- bei Scriptsprachen kann die Unterscheidung nicht gemacht werden
- Class Files müssten von daher sowieso gehen, weil Bibliotheken so vorliegen
-->
Am schönsten wäre es im Grunde, wenn man dem SM alles geben könnte, was man hat, und er das Maximum herausholt. Wenn beides da ist und inkonsistent, dann soll er das melden.


Was sind denn Fragen an den Code? Die meisten Fragen sind realistisch doch eher: "ich versteh hier nix, was ist denn hier was?"
--> Also die Fragen nach Übersicht. 
--> Diese Frage kann davon ausgehen, dass es keinen unbenutzten Code gibt. (Ansonsten kann wie unten geklärt werden, was unbenutzt ist, und dieser soft (separate Löschtabelle) oder hard gelöscht werden)
Was sind Antworten auf die Frage nach Orientierung?
- Klassen und Methoden werden mit Tags versehen:
	- Klassen
		- Reines Datenobjekt
			- mit equals / hashcode support
			- mit kaputtem equals- oder hashcode-support
		- toString support
		- immutable
	- Methoden
		- Getter
		- Setter
		- Nop-op
		- virtual, final, effectively final (wird nirgendwo überschrieben --> benötigt das Wissen darüber, ob der Code vollständig vorliegt)
		- NOP


Eine weitere Frage ist die nach unbenutztem Code. Die lässt sich beantworten:
- welche Klassen werden nicht statisch benutzt?
- welche Methoden werden nicht statisch benutzt?
- wo finden dynamische Verwendungen statt? Welche davon können durch Programmanalyse "verstatischt" oder zumindest statisch eingegrenzt werden?


Weitere Fragen sind die nach dem Verhalten einzelner Codestücke:
- wie verhält sich f(x=5)? Wie verhält sich f(x<5)? Wie wenn static int foo = 42?
- Unter welchen Bedingungen fliegt gleich eine IllegalArgumentException oder NPE?
- Allgemeiner: Was sind die "Grenzen", wo sich das Verhalten radikal ändert? Im Prinzip werden hier die verschachtelten ifs "flachgedrückt", durch die
	vorhergehenden Befehle "durchgedrückt" und aus deren Bedingungen eine Partition der Funktionsparameter gebaut.

Weitere:
- copy & paste code, auch mit Unterschieden
- toter Code
- abhängigkeiten
- "high-level-Architektur" <-- muss klarer definiert werden
- NICHT: Coding-Richtlinien, insbesondere die oberflächlichen (Formatierung, Naming, cyclo-complexity, ...). Dafür ist Sonarqube da.
- EVTL: Sicherheitslücken. Auch dafür ist eigentlich Sonarqube da. Der Übergang ist aber fließend.
- Implementierung in einer low-level-Sprache (z.B. Java -> Native, auch Assembler und Embedded-Kram)
- Suche nach Race Conditions
- Was-wäre-wenn (näher zu definieren)
- disassembling
- "ganzheitliche Problemsuche" inkl. DB-Daten, Konfiguration etc., was alles nicht Teil des Codes ist; außerdem soll es in der Lage sein, ein vorhandenes
	Projekt zu analysieren, wo auch evtl. ein komplizierter Build stattfindet. Andere Tools kommen nicht damit klar, wenn sie den Build nicht verstehen.
- Refactoring-Vorschläge (idealerweise so automatisiert, dass man diese nur noch per Knopfdruck bestätigen muss. Das braucht aber ggf. gute Integration in IDEs, oder
	es muss selbst Refactoring-Wissen haben. Als eine 80%-Lösung reicht es aber, die Vorschläge zu machen.)
- ideal wäre die Möglichkeit, Code zu analysieren, der nicht compiled
- unklar: Analyse zur Laufzeit. Das kann helfen, kann aber auch total irreführend sein.
- Abhängigkeiten vom Compiler etc. finden (geht aber auch eher in den Sonarqube-Bereich rein)
- Erkennung von Patterns (Class Patterns wie Visitor; Architecture Patterns wie MVC)
- Erkennung von "Projekttypen" (z.B. anhand Frameworks) und Hinweis auf Regeln, die in diesem Projekttyp gelten)
	-> Beispiel-Frage: "was ist in welchem Ordner?"
	-> Antwort: "Dies ist ein CakePHP 2 Projekt. Im Ordner "src" liegt der Quellcode; in "lib" liegt CakePHP selbst; in src/controller sind die Controller-Klassen (Link auf Doku); ..."
- Welche möglichen "Pfade" gibt es (Methodenübergreifend) durch den Code?
- Erkläre folgenden Regex (in Regex-Dialekt XYZ): ...
- Welche Exceptions können hier fliegen (also wirklich, nicht nur Herumgerate)
- Welche "Effekte" kann ein System haben?
	-> wohin können Netzwerkverbindungen aufgemacht werden? Wohin werden HTTP-Requests gesendet?
	-> auf welche lokalen Dateien wird zugegriffen?

Andere Wichtige Features:
- hier entsteht eine Unmenge an Information. Es ist wichtig, diese nicht nur strukturiert darzustellen, sondern auch leicht navigierbar zu machen! Also braucht es einen "Browser" für das Ergebnis, welcher dann auch mit einem Code-Browser einhergeht. Integration in eine IDE wäre cool; webbasierte Darstellung eine Alternative, wo man nicht von ewig vielen Tools abhängig ist, aber dann braucht es natürlich einen Syntax Highlighter (-> CodeMirror!). Beispiele:
	- Klick auf eine Methode: "Zeige mir, wie diese Methode ablaufen kann!"
		- Split nach Parametern / external State (falls größtenteils gleich, diesen Split "nach innen" verschieben)
		- dabei müssten Varianten ausgeschlossen werden, die nach Analyse von anderem Code "nicht vorkommen können"
			-> Invarianten! Z.B.
				"Bei einem fertig erzeugten Objekt der Klasse X ist das feld F niemals null und niemals der Leerstring"
				"Ein Objekt der Klasse K ist niemals Teil einer zyklischen Datenstruktur" (Interna der Standardbibliothek ausgenommen,
					soll heißen Object-Class-Reference wird ignoriert; String gilt als Leaf; ...
				"Ein Objekt der Klasse K bildet immer mit einem Objekt der Klasse A eine zyklische Struktur"
		- jeweils die Abfolge von Befehlen; bei Methodenaufrufen, in welche Methode das reinführen kann (wenn nur 1 möglich, dann Hinweis und warum)
		- dabei Sonderbehandlung von Standardmethoden (z.B. Klasse String), wobei diese auf Wunsch abgeschaltet werden kann
- Plugins sollten automatisch nachgeladen werden, oder zumindest der Vorschlag gemacht werden. Dadurch kann viel spezifisches Wissen verfügbar gemacht werden,
	z.B. über bestimmte Frameworks und Bibliotheken.
	Sicherheitsbedenken werden dabei aufkommen. Dazu wird erst mal viel Review stattfinden müssen, d.h. nur im Sourcecode submittet. Idealerweise kann man
	später aber genau über dieses Tool die Plugins untersuchen, ob sie irgendwas schädliches tun!

Prestige-Beispiele:
- vollständige Dokumentation des Linux-Kernel-Codes
- disassembling eines bekannten Projekts (z.B. Doom oder Quake; Im Java-Umfeld sowas wie Elasticsearch, Eclipse, Tomcat, Minecraft)
	-> hier könnte man z.B. sagen: Wir würden gerne Minecraft disassemblen, aber die rechtliche Siutation ist uns zu heikel. Und dann das Programm so
		vorbereiten, dass Minecraft nirgendwo verlinkt ist, aber wenn man den Link einträgt, out of the box komplett analysiert werden kann.

------------------------------------

v1:
- nur ein classloader
- geht davon aus, dass aller code schon compiled wurde
--> das sind alles nur "v1-Annahmen" !!!

Wie kann das Analysieren überhaupt gehen?
-> Modell der Klassenhierarchie, Methoden, Felder
	Das kann direkt aus den Classfiles aufgebaut werden.
	Erst mal nur auf Java abzielen. Das kann später gut erweitert werden.
-> Kontrollflussanalyse -> entweder ein CFG oder SSA-Pseudo-Assembler wie bei LLVM
	(ist ein CFG auch SSA? möglicherweise wäre das dann die sinnvollste Variante)

------------------------------------

Das Frage-Antwort-Memoize-Prinzip ist schwach! Sinnvoller wäre ein "Erkenntnis-Sammel-Prinzip", weil es darauf setzt, dass eine Erkenntnis zu einer neuen führen kann. Frage-Antwort wäre sinnvoll,
wenn klarer wäre, woher die Antwort kommt.

Also: Jede Erkenntnis kann zu einer neuen führen, und die wieder zu einer neuen. Das klingt nach Event Listener:
- es gibt eine zentrale listener registry
- die root-information (z.B. Ordner, VCS-URL) ist eine Erkenntnis
- jede Erkenntnis wird an alle Listener gesendet
- das passiert aber nur einmal. Die Registry merkt sich jede gesendete Erkenntnis und sendet sie nicht nochmal
- am Ende kann man das Ergebnis ggf. durch eine Frage filtern. Dieser Teil ist noch unklar, aber das wird offensichtlich, wenn bekannt ist, welche Erkenntnisse sich da so anhäufen

Beispiele:
- ClassFile-Ordner -> ClassModels
- ClassModels -> verwendete Frameworks
- ClassModels -> wo wird überall Reflection verwendet
- ClassModels -> Main-Klassen
- wo Reflection -> wo werden beliebige Konstruktoren aufgerufen
- wo Reflection -> wo wird auf Private Fields zugegriffen
- ClassModels, wo wird auf Private Fields zugegriffen --> wird auf beliebige Private Fields zugegriffen?
- ClassModels, Main-Klassen -> Command-Line Parameters

Dieses Prinzip lässt sich auch sehr einfach um beliebiges Wissen aus Plugins erweitern.

---

So ganz ist es das aber noch nicht. Für diverse Erkenntnisse gibt es verschiedene "Versionen" -- erst kommt eine einfache Version, später eine verbesserte (die sich unterscheiden kann),
und evtl. auch wegen einer Art "Race Condition" (Reihenfolge der Listener-Aufrufe; kann auch tatsächlich in Threads passieren) kann eine Erkenntnis "verspätet" kommen und dadurch schlechter
sein, als eine frühere Erkenntnis derselben Art. Dazu muss jede Erkenntnis erst mal genau dokumentieren, wie sie zustande gekommen ist -- dann kann jeder potentielle Consumer zumindest alle
Erkenntnisse mergen. Wenn es bei einer Art von Erkenntnis eine klare Rangfolge gibt (besser vs. schlechter), dann kann diese ja über Methoden abrufbar sein, was es für Consumer einfacher macht.

Trotzdem ist die Frage, was davon im Basis-System abgebildet wird. Gibt es eine Art "Key" für Erkenntnisse, so dass zwei Erkenntnis-Objekt mit demselben "Key" immer zwei Versionen darstellen,
wo nur eine richtig sein kann (aber evtl. keine der präsentierten)? Wenn jedes Erkenntnis-Objekt dokumentiert, wie es zustande gekommen ist, dann ist jedes davon richtig; sie beantworten verschiedene
Fragen. Wenn man das aber auf die Spitze treibt, dann ist es nicht viel hilfreicher als eine Frage-Antwort-Engine. Etwas besseres bekommt man zumindest, wenn die Erkenntnis-Objekt interfaces
implementieren, wodurch ein Consumer alle Erkenntnisse mit bestimmten Interfaces verarbeiten kann. Dann muss immer noch entschieden werden, welches "richtiger" ist.

Ein konkretes Beispiel: Wo wird eine Klasse instanziiert?
- alle Aufrufe des Constructors
- alle Reflection-Verwendungen
- Reflection-Verwendungen gefiltert aufgrund von anderen Erkenntnissen

Ein Ansatz aus dem manuellen Vorgehen wäre es, eine Widerspruchs-Erkennung zu benutzen. Dann müsste nachfolgend der
Widerspruch aufgelöst werden -> "was stimmt denn jetzt?" Danach würde dann eine der Aussagen ungültig, alle
Schlußfolgerungen auch, was evtl. die konkurrierende Aussage *auch* ungültig macht und man hat gar nichts mehr. Dabei
wäre es eigentlich richtig, zu erkennen, dass in der Kette irgendwo die Aussagen *doch* gültig werden, nur mit
anderer Begründung -- was man aber noch schwerer erkennen kann. Das führt so zu nichts.

Besser ist da schon der Ansatz mit Interfaces, so dass verschiedene Grundlagen auf dieselbe Art zu einer Schlußfolgerung
führen können. Z.B. kann die Liste der direkten Konstrukturaufrufe genauso wie die Liste von Reflection-Konstruktoraufrufen
zu einer Liste von instanziierten konkreten Klassen führen. Beide "wissen", dass sie nicht exklusiv sind, aber beide
können auf dieselbe Art verwendet werden --> Interface! Zusammen mit Annahmen (keine Konstruktoraufrufe aus
Native Code heraus -> das sollte ein Default, aber explizit und sichtbar sein) wird daraus eine Abschließende Liste von
instanziierten Klassen.

Wo sind die Vorteile zu Anfrage-Antwort? Die Interfaces sind ein Vorteil, aber das alleine ist noch zu schwach. Wichtig
wäre es, dieselbe Erkenntnis auf verschiedenen Wegen finden zu können. Das Hauptproblem scheint dabei zu sein, dass man
für eine brauchbare Erkenntnis eine "beidseitige" Aussage braucht: Also bei den Konstruktoraufrufen eine Liste ohne
falsche Elemente und ohne fehlende Elemente. Die lässt sich schlecht einseitig durch Plugins erweitern.

Weiter gedacht ist das Problem, dass man eine definitive Aussage will, aber auf der Basis von "mitwirkenden" Plugins.
Zu allererst ist mal zu klären, ob diese Wunschvorstellung überhaupt realistisch / sinnvoll ist. Ich will es nicht
von vornherein ausschließen: Die Beweisführung muss nach allen Seiten hin hieb- und stichfest sein, aber der Weg, auf
dem die Beweisführung gefunden wird, kann beliebig schwammig sein.
-->
Wenn man das weiterdenkt, wird langsam klar, wie die Wunschvorstellung konkret aussieht: so etwas ähnliches wie Verifun,
aber für prozedurale Sprachen und mit Heuristiken, welche die zu beweisenden Aussagen automatisch generieren.
-->
Nach nochmaligem drüber Nachdenken kann ich das nur bestätigen. Schwammige Aussagen über den Code kann man in mehreren
Stufen auch selbst treffen -- die sind aber selten viel Wert, weil man bei "interessantem" Code fast immer merkt, dass es
doch ganz anders ist. Wasserdichte Aussagen sind das wirklich wertvolle:
- als Ausgangspunkt sollte für die meisten Aussagen klar sein, welcher Code (maximal) verwendet wird. Eine solche Obergrenze lässt sich aber fast immer
	finden, notfalls mit Zwischenschritten. Meistens ist es eine Kombination aus Basiscode, Plugins von irgendwoher und Code aus der Datenbank.
	Erst wenn Downloads von beliebigen Quellen erlaubt sind, wird es haarig. Das passiert aber nicht sehr oft.
- Damit sind dann Obergrenzen bekannt, welche Klassen es gibt -- und damit auch mögliche Implementierungen für jede Methode.
	--> Idee: Hier kann im schlimmsten Fall herauskommen, dass doch Code von woandersher kommt (z.B.: es war in der ersten
		Runde nicht bekannt, dass Code in der DB liegt). In diesem Fall wäre es die einfachste Lösung, dass die Engine sich
		gar nicht wieder "erholen" kann, sondern mit dem Widerspruch diese Runde abgebrochen wird. Dann muss der Benutzer
		die Annahmen anpassen (z.B. Datenbankzugang herstellen) und das Tool neu starten. 
	--> Im schlimmsten Fall kann ein übergeordnetes Tool das tun.
- Auf dieser Grundlage kann dann evtl. Stück für Stück erkannt werden, welche von diesen Klassen wirklich verwendet werden.
	Beispiel:
	- bekannte Frameworks, die Reflection einsetzen, und wie diese sich verhalten (z.B. Wissen darüber, wie Spring-XML-Dateien funktionieren)
	- Klassen, deren Konstrukturen nicht zu der Art und Weise passen, wie Konstrukturen per Reflection aufgerufen werden (Anzahl und Typ der Parameter)
	- Reflection-verwendender Code, der niemals ausgeführt wird

Um nochmal zu wiederholen, was der Unterschied zu request-response ist:
- Eine Erkenntnis kann verwertet werden, ohne dass bekannt ist, wie sie zustandegekommen ist. Bei request-response müsste man aufgrund der Frage
	wissen, wie man zu einer Antwort kommt. Das heißt, RR müsste mit Response-Contributoren arbeiten, um dasselbe zu erreichen. Auf diesem Weg wäre
	RR vermutlich auch gleichwertig, und es stellt sich schon die Frage, ob das nicht sinnvoller wäre.
	--> Das gibt es das "Keine-Zyklen-Problem": RR kann nicht in mehreren Zyklen eine immer bessere Version einer Antwort finden. Es würde sich dabei
		in einer Endlosschleife verfangen. Listeners dagegen haben zwar das Problem, die Versionen als verschiedene Aussagen zu taggen, können diese
		aber anhäufen und dabei verbessern.
- RR ist zielgerichtet, Listeners sind ein "Shotgun-Ansatz". Aber genau dieser ermöglicht die schrittweise Verbesserung. Wohlgemerkt: Der Vorteil ist NICHT,
	dass man auch auf Umwegen zum Ziel kommt -- das kann auch RR (auch wenn es dabei einen Teil der Zielgerichtetheit verliert). Der Vorteil ist, dass auf
	dieselbe Fragen schrittweise immer bessere Antworten gegeben werden können, und das kann RR nicht.

Der Listener-Ansatz wäre also:
- Jede Erkenntnis ist korrekt und verliert niemals an Gültigkeit. Maximal kann sie von einer neueren Erkenntnis subsummiert werden und könnte dann aus
	Performancegründen verworfen werden -- das Ergebnis wird aber nicht verfälscht, wenn man sie behält.
- Demnach gibt es auch keine Versionen, keine Keys für die Erkenntnisse etc.
- Eine Gleichheit unter Erkenntnissen muss definiert werden, wenn ansonsten eine Erkenntnis in einer Kette von Schlußfolgerungen zu sich selbst führt.
	Dann muss aufgrund der Gleichheit dieses erkannt werden und nicht an die Listener weitergegeben, um eine Endlosschleife zu vermeiden.
	-> equals / hashCode überschreiben, wenn diese Gefahr besteht, ansonsten ist das nicht nötig. Dann gilt Gleichheit aufgrund Objektidentität.

Überlegung, wie man mit Problemen umgeht wie z.B. welche Ordner/JARs zum Classpath gehören, auch abschließend:
- man kann natürlich in jede Schlußfolgerung die Annahmen integrieren. Das bläht es aber ganz schön auf. Ist die Frage, ob man diese "Erkenntnisse", die
	ja alle als wenn-dann formuliert sind, noch gut verarbeiten kann.
- ansonsten kann man auch Annahmen als "global" speichern und muss dann ggf. diese verwerfen und neu anfangen. Das klingt schon besser, erhöht aber
	natürlich auch die Laufzeit.
- weitere Idee: Man speichert nicht die Annahmen als Datenfelder in den Erkenntnissen, sondern verlinkt frühere Erkenntnisse. Die Erkenntnisse sind dann
	ein potentiell unbegrenzt wachsender Baum aus Erkenntnis-Knoten, deren Vorgänger jeweils die Annahmen und früheren Erkenntnisse und deren Nachfolger
	die daraus abgeleiteten Schlußfolgerungen sind. "Vorgänger" und "Nachfolger" hier zeitlich; Objektgraph-mäßig verlinkt jeder Knoten auf seine
	Vorgänger, d.h. die Objektreferenzen laufen in die Gegenrichtung.
	-
	Dann wäre das Grundprinzip nicht "Listener" sondern "Pattern Matching": Es wird jeweils ein Pattern gemacht und daraus ein neuer Knoten erzeugt.
	-
	Wesentlicher Unterschied: Die Pattern-Matcher dürfen im Gegensatz zu den Listenern nicht stateful sein, weil sie auch mal spekulativ auf unbestätigte
	Vermutungen losgelassen werden.
	-
	Die Wurzelknoten sind die grundsäzlichen Annahmen, z.B. Angaben über den Classpath bzw. über Root-Ordner. Wenn man eine Annahme hinzufügt, ist das
	eine neue Wurzel; wenn man eine Annahme wieder wegnimmt, verschwinden alle dessen Nachfolger wieder. Deshalb ist es wünschenswert, dass jede
	Schlußfolgerung nur diejenigen Knoten als Vorgänger verlinkt, die auch wirklich nötig waren. Das ist aber nur eine Performancefrage; auf keinen
	Fall darf ein verwendeter Vorgänger nicht verlinkt werden! Und "verwendet" heißt schon: ein einzelnes "if" über dessen Existenz. Von daher
	überlässt man das am besten gar nicht dem Schlußfolgerungscode sondern dem Pattern Matcher. Sonderfälle wie z.B. "Knoten B wird nur verwendet,
	wenn das Feld 'foo' in Knoten A auf true steht" -> kann man in den Pattern Matcher einbauen, indem dieser mit Objekten konfiguriert wird. Das
	ist besser, als zu riskieren, dass Vorgängerknoten fehlen.
	-
	In einem endgültigen Ergebnis kann dann jede Schlußfolgerung mit den nötigen Annahmen gelistet werden. Nötige Annahmen sind alle (direkten und
	indirekten) Vorgänger-Wurzelknoten. Der Benutzer kann dann z.B. diese pinnen (falls es eine generierte Annahme war) oder auch dem Programm
	mitteilen, dass sie nicht stimmt (d.h. das Negat pinnen). Jede nicht gepinnte Annahme kann man als Frage an den Benutzer richten, zur Recherche
	oder auch um zielgerichtet mit dem Sensemaker zu beweisen, dass sie wahr ist.
	-
	Reduzierte Annahmen und "Rettung" von Schlußfolgerungen: Weit entwickelte Matcher können sagen, dass sie einen Knoten gar nicht "komplett" als
	Annahme brauchen, sondern nur eine schwächere Aussage. Also nicht A->B sondern A->A'->B, wobei der Matcher für A->B sich aus den Fingern saugt,
	welche Aussage A' ausreichend wäre. Im Prinzip ist hier sowas wie eine temporäre private Matcher-Registry nötig: Das Matchen und Knoten
	erzeugen funktioniert weiterhin genauso (vor allem, damit keine Vorgänger fehlen), aber es werden private Matcher eingesetzt, die man im
	normalen Ablauf nicht haben will, weil sie dort nur unbrauchbare Knoten erzeugen würden. Auch ggf. für diesen einen Fall zugeschnittene
	Matcher, die man normal nicht verwenden kann, weil man dazu eine unendlich große Zahl von Parametrisierten Matchern bräuchte.
	Sinn ist die "Rettung" einer Schlußfolgerung, nachdem die Annahme widerlegt wurde: Wenn eine Annahme X zu A geführt hat, also
	X -> ... -> A -> B, und X wird widerlegt, dann kann man mit der reduzierten Annahme A' evtl. eine schwächere Annahme Y finden, mit der B immer
	noch folgt: X -> ... -> A -> A' -> B; X platzt, aber Y gilt, so das Y -> ... -> A' -> B. Dann ist B gerettet.
	Beispiel: Wenn erkannt wird, dass es Reflection-Zugriffe auf private Felder gibt, sind viele Annahmen dahin. Wenn man aber zeigen kann,
	dass das nur einzelne Klassen betrifft, dann kann statt der Annahme "kein Reflection-Zugriff auf private Felder" die schwächere Annahme
	"kein Reflection-Zugriff auf private Felder dieser Klasse" genommen werden und die Schlußfolgerung ist gerettet.
		--> dieser ganze Abschnitt ist Optimierung. Ohne das muss man im schlimmsten Fall einen Teilbaum immer wieder in ähnlicher Form
			neu aufbauen, wegwerfen, ähnlich neu aufbauen etc.
	-
	Standardannahmen: Ein Satz von "üblichen" Annahmen sollte als Standard verfügbar sein, evtl. sogar als Default gelten. Damit lassen sich viele
	Fälle abdecken, so dass das Tool überhaupt erst mal was erreicht. Im schlimmsten Fall muss man davon dann welche rausnehmen. Bsp.:
		- kein Reflection-Zugriff auf private Felder
		- kein Reflection-Zugriff auf private Konstruktoren
		- keine nachträglich gebauten ClassLoader, keine Aufrufe von defineClass (-> Code ist vollständig bekannt; wird öfters platzen, aber hilft trotzdem erstmal)
		- keine load-time-bytecode-manipulation o.ä., d.h. die Klassen entsprechen den Class Files
		- kein custom boot class path, d.h. standardverhalten der Java class lib kann angenommen werden
		- keine Manipulierte Virtual Machine (das macht als "Annahme" wenig Sinn, weil jede Java-Regel sie braucht -- wenn die VM manipuliert
			wurde, kann keiner der Standardmatcher mehr funktionieren. Besser ist, per Definition zu sagen, dass das nicht mehr Java ist)

Erkenntnisse:
- classpath XYZ wird potentiell verwendet
- Die Liste [...] enthält alle verwendeten Classpaths (kann aber ggf. welche enthalten, die nicht verwendet werden)
- Klasse XYZ wird potentiell verwendet
- Die Liste [...] enthält alle verwendeten Klassen (kann aber ggf. welche enthalten, die nicht verwendet werden)
- Die Liste L = [...] besteht nur aus Subklassen der Klasse K und alle verwendeten Subklassen von K sind in L; es kann aber
	sein, dass L Subklassen von K enthält, die nicht verwendet werden.
	Bemerkung: Falls L=[], dann ist K effektiv final. Falls K formal final oder private ist, kann direkt L=[] festgestellt werden, ohne
		andere Klassen anzusehen.
- Die Liste L = [...] besteht nur aus Überschreibungen der Methode M (Klasse, Name, Signatur) und alle verwendeten Überschreibungen von M
	sind in L; es kann aber sein, dass L Überschreibungen von M enthält, die nicht verwendet werden.
	Bemerkung: Falls L=[], dann ist M effektiv final. Falls M formal final oder private ist, kann direkt L=[] festgestellt werden, ohne
		andere Klassen anzusehen.
- Es gibt nur eine Implementierung von Interface I.
- Es gibt nur eine Implementierung von der abstrakten Methode (auch Interface-Methode) M.
- Klasse K wird nicht instanziiert.
- Klasse K wird nicht verwendet.
- Methode M wird nicht verwendet.
- Klasse K ist immutable (thread-safe durch final fields oder thread-unsafe).
- Klasse K überschreibt equals / hashCode
- Klasse K überschreibt nur equals oder nur hashCode
- Klasse K ist eine Sammlung statischer Methoden (enthält min. 1 statische Methode; wird nicht instanziiert; keine nichtstatischen Member)
- Methode M liefert immer denselben Returnwert (der aber ein mutable object sein kann)
- Methode M entspricht einer Konstanten (liefert immer denselben Wert; dieser ist ein Primitivwert, null oder immutable)
- Methode M hat maximal die folgenden Seiteneffekte: [...]
- Methode M liest maximal die folgenden externen Variablen: [...]
- Methode M kann durch folgenden Kontrollflussgraphen dargestellt werden
	- reduziert durch frühere Erkenntnisse und Annahmen
	- zunehmend mit highlevel nodes (und diese können durch Plugins beigesteuert werden)
	- jede Transformation des CFG kann erklärt werden

Zusätzlich zu Annahmen und Erkenntnissen sollte es möglich sein, gezielte Fragen zu stellen. Diese verwerten dann die Erkenntnisse.
- Wie kann ein Aufruf von Methode M ablaufen?
	-> das kann nur beantwortet werden, wenn als Annahme feststeht, dass M verwendet wird. Ansonsten wird der ganze Schlußfolgerungscode
		falsche Ergebnisse liefern. Z.B. wird, wenn M nicht verwendet wird, eine aufgerufene Methode N "zusammengekürzt", weil stärkere
		Annahmen über deren Parameter gemacht werden können. Wenn diese gekürzte Variante dann doch für M benutzt wird, gibt es falsche
		Ergebnisse.
- Auf welchen Wegen ist Stelle X im Code erreichbar?
	- verfolgt die Ausführungspfade rückwärts
- UML-like Klassendiagramm
- Datenbankdiagramm (auf Basis von Constraints, mit dem Hintergedanken dass man diese umgehen kann)
	--> Annahme in den Default-Annahmen: Constraints werden respektiert

